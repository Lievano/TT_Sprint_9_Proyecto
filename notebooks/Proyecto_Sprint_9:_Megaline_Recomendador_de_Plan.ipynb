{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da672230",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Proyecto del Sprint 9:\n",
    "## Megaline | Recomendador de Plan (Smart = 0, Ultra = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350f684",
   "metadata": {},
   "source": [
    "<a id=\"indice\"></a>\n",
    "## Índice\n",
    "- [1. Introducción y objetivo](#intro)\n",
    "- [2. Protocolo y criterios](#protocolo)\n",
    "- [3. Carga y validaciones de datos](#carga)\n",
    "- [4. Partición de datos (train/valid/test)](#particion)\n",
    "- [5. Modelos baseline (comparación inicial)](#baseline)\n",
    "- [6. Modelos base supervisados](#supervisados)\n",
    "- [7. Optimización de hiperparámetros (Random Forest)](#optimizacion)\n",
    "- [8. Evaluación final en test](#evaluacion)\n",
    "- [9. Pruebas de cordura](#cordura)\n",
    "  - [9.1 Pruebas básicas (caja negra)](#cordura-basicas)\n",
    "  - [9.2 Pruebas avanzadas (diagnóstico profundo)](#cordura-avanzadas)\n",
    "- [10. Conclusiones](#conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46b0f3",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# 1. Introducción y objetivo\n",
    "**Introducción:**  \n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.  \n",
    "\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud.  \n",
    "\n",
    "**Objetivo:** construir un clasificador para recomendar **Smart (0)** vs **Ultra (1)** con **accuracy ≥ 0.75** en test bloqueado.  \n",
    "\n",
    "**Contexto:** migración desde planes heredados maximizando conversión sin inflar reclamos.  \n",
    "\n",
    "**Importancia:** asignación del plan afecta ingresos y satisfacción.  \n",
    "Métricas/criterios: accuracy (principal), precision/recall/F1 por clase, matriz de confusión; IC 95% por bootstrap.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c2ff7",
   "metadata": {},
   "source": [
    "<a id=\"protocolo\"></a>\n",
    "# 2. Protocolo y criterios\n",
    "**Objetivo:**  \n",
    "Importar todas las librerías necesarias para análisis, modelado y métricas; fijar parámetros globales de reproducibilidad; y definir funciones auxiliares para centralizar el cálculo y presentación de métricas.  \n",
    "\n",
    "**Contexto:**  \n",
    "El proyecto requiere múltiples etapas: partición de datos, entrenamiento de modelos (árboles, regresión logística, random forest), validación con CV, y evaluación final con métricas estándar. Además, la reproducibilidad es fundamental para que los resultados sean consistentes en distintas corridas.  \n",
    "\n",
    "**Importancia:**  \n",
    "- **Imports ordenados:** concentra todas las dependencias en un bloque para claridad y trazabilidad.  \n",
    "- **Semilla global (`RANDOM_STATE`):** garantiza que los splits de datos, el muestreo y el entrenamiento de modelos sean replicables.  \n",
    "- **Supresión de warnings:** limpia la salida en notebook, enfocándose en lo relevante para el análisis.  \n",
    "- **Función auxiliar (`resumen`):** estandariza el reporte de métricas, evitando repetir lógica en cada modelo. Esto asegura consistencia y comparabilidad.  \n",
    "\n",
    "**Métricas/criterios:**  \n",
    "- **Accuracy:** proporción global de aciertos.  \n",
    "- **Precision, Recall, F1:** métricas por clase, necesarias para evaluar el balance Smart/Ultra.  \n",
    "- **Matriz de confusión:** diagnósticos sobre errores específicos entre clases.  \n",
    "- **Reporte por clase (`classification_report`):** resumen interpretativo que combina las métricas clave.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fc4d7-337c-48a3-b987-f52877182181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Imports]: librerías generales\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report, balanced_accuracy_score, f1_score, roc_curve, precision_recall_curve, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# [Configuración global]: reproducibilidad y supresión de warnings\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# [Función auxiliar]: cálculo de métricas estándar\n",
    "def resumen(y_true, y_pred, titulo=\"Resumen\", y_train=None, pos_label=1):\n",
    "    from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bacc = balanced_accuracy_score(y_true, y_pred)\n",
    "    # orden fijo de clases: 0 y 1\n",
    "    prec, rec, f1, sup = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=[0, 1], zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "\n",
    "    # opcional: accuracy “esperada” del dummy que predice la clase mayoritaria de y_train\n",
    "    acc_esp = None\n",
    "    if y_train is not None:\n",
    "        maj_train = np.bincount(np.array(y_train)).argmax()\n",
    "        acc_esp = float(np.mean(np.array(y_true) == maj_train))\n",
    "\n",
    "    print(f\"\\n\\n*** {titulo} ***\\n\")\n",
    "    print(\"Matriz de confusión (filas=verdad, cols=pred):\\n\\n\", cm)\n",
    "    print(\n",
    "        \"\\nAccuracy: {:.3f} | Balanced Acc: {:.3f}{}\".format(\n",
    "            acc, bacc,\n",
    "            f\" | Acc_esperada_dummy: {acc_esp:.3f}\" if acc_esp is not None else \"\"\n",
    "        )\n",
    "    )\n",
    "    # Tabla limpia por clase (prec, rec, f1, supp)\n",
    "    tabla = pd.DataFrame(\n",
    "        {\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1\": f1,\n",
    "            \"support\": sup.astype(int),\n",
    "        },\n",
    "        index=[0, 1],\n",
    "    )\n",
    "    print(\"\\nReporte por clase:\\n\")\n",
    "    print(tabla.to_string(float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "    return acc, bacc, prec, rec, f1, sup, cm, acc_esp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccc933",
   "metadata": {},
   "source": [
    "<a id=\"carga\"></a>\n",
    "# 3. Carga y validaciones de datos\n",
    "**Objetivo:**  \n",
    "Asegurar que el dataset `users_behavior.csv` se encuentra disponible en rutas candidatas, validarlo contra el esquema esperado y comprobar su calidad mínima (columnas, nulos, duplicados y balance de clases).  \n",
    "\n",
    "**Contexto:**  \n",
    "Los modelos posteriores dependen de la correcta lectura y consistencia del dataset. Si faltan columnas, hay valores nulos o duplicados, o si la variable objetivo está desbalanceada, el desempeño y la interpretabilidad del modelo se ven comprometidos.  \n",
    "\n",
    "**Importancia:**  \n",
    "- **Ruta dinámica:** permite trabajar tanto en entornos locales como en ejecución en servidor (dos rutas candidatas).  \n",
    "- **Validación de esquema:** garantiza que el CSV incluye las 5 columnas clave definidas por el negocio (`calls, minutes, messages, mb_used, is_ultra`).  \n",
    "- **Chequeo de nulos y duplicados:** detecta problemas de calidad de datos que podrían sesgar o romper el entrenamiento.  \n",
    "- **Distribución de clases:** conocer la proporción de Smart (0) vs Ultra (1) desde el inicio ayuda a interpretar métricas y definir la necesidad de técnicas de balance.  \n",
    "\n",
    "**Métricas/criterios:**  \n",
    "- **Integridad de columnas:** todas las columnas esperadas presentes, sin faltantes.  \n",
    "- **Nulos:** idealmente cero por columna; si existen, decidir imputación o descarte.  \n",
    "- **Duplicados:** deberían ser cero; en caso contrario, limpiar antes de entrenar.  \n",
    "- **Distribución objetivo (`is_ultra`):**  \n",
    "  - Conteo absoluto por clase (value_counts).  \n",
    "  - Proporción relativa (% de cada clase).  \n",
    "  - Se utilizará para estratificación en los splits y como referencia para interpretar la métrica de accuracy.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c30858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas candidatas para encontrar el CSV en distintos entornos\n",
    "CANDIDATE_PATHS = [Path('../data/users_behavior.csv'),\n",
    "                   Path('./data/users_behavior.csv')]\n",
    "\n",
    "# Seleccionar la primera ruta que exista\n",
    "DATA_PATH = next((p for p in CANDIDATE_PATHS if p.exists()), None)\n",
    "assert DATA_PATH is not None, 'No se encontró users_behavior.csv'\n",
    "\n",
    "# Leer el dataset\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Validar que todas las columnas esperadas están presentes\n",
    "expected_cols = ['calls','minutes','messages','mb_used','is_ultra']\n",
    "missing = set(expected_cols) - set(data.columns)\n",
    "assert not missing, f'Faltan columnas: {missing}'\n",
    "\n",
    "# Contar nulos y duplicados\n",
    "nulls = data.isnull().sum()\n",
    "dups = data.duplicated().sum()\n",
    "\n",
    "# Valores numéricos negativos\n",
    "negs=(data[[\"calls\",\"minutes\",\"messages\",\"mb_used\"]] <= 0).all().all()\n",
    "\n",
    "# Revisar balance de la variable objetivo\n",
    "class_counts = data['is_ultra'].value_counts().sort_index()\n",
    "class_ratio = class_counts / class_counts.sum()\n",
    "\n",
    "# Resumen de validaciones\n",
    "print(f'Ruta: {DATA_PATH}\\n')\n",
    "# Validar tipos\n",
    "print(f\"\\n{data.info()}\")\n",
    "print(\"\\nValores negativos:\", negs)\n",
    "print('\\nNulos por columna:\\n', nulls)\n",
    "print('\\nDuplicados:', dups)\n",
    "print('\\nDistribución objetivo:', class_counts.to_dict(), class_ratio.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f8268",
   "metadata": {},
   "source": [
    "<a id=\"particion\"></a>\n",
    "# 4. Partición de datos (train/valid/test)\n",
    "**Objetivo:**  \n",
    "Dividir el dataset en subconjuntos de entrenamiento, validación y prueba de manera estratificada, preservando la proporción de clases en cada split.  \n",
    "\n",
    "**Contexto:**  \n",
    "- El conjunto de entrenamiento (60%) se usa para ajustar los modelos.  \n",
    "- El conjunto de validación (20%) permite comparar modelos y tunear hiperparámetros sin sesgar los resultados finales.  \n",
    "- El conjunto de prueba (20%) se mantiene aislado hasta el final para obtener una estimación honesta del desempeño real.  \n",
    "\n",
    "**Importancia:**  \n",
    "- **Estratificación:** asegura que la proporción Smart/Ultra se mantenga en todos los splits.  \n",
    "- **Separación adecuada:** evita fugas de información y sobreajuste.  \n",
    "- **Control de tamaños:** garantiza suficientes observaciones en cada subconjunto para métricas confiables.  \n",
    "\n",
    "**Métricas/criterios:**  \n",
    "- **Tamaño de los splits:** 60% train, 20% valid, 20% test.  \n",
    "- **Proporción de clase objetivo:** se imprime para verificar que se mantiene la distribución en cada subconjunto.  \n",
    "- **Reproducibilidad:** el uso de `RANDOM_STATE` asegura consistencia entre corridas.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['calls','minutes','messages','mb_used']\n",
    "X = data[features].copy()\n",
    "y = data['is_ultra'].astype(int).copy()\n",
    "\n",
    "# Split 1: 60% train, 40% temporal (valid+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Split 2: 20% valid, 20% test (50/50 a partir del 40% temporal)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Resumen de proporciones en cada split\n",
    "for name, s in [\n",
    "    (\"Total 100%\", y),\n",
    "    (\"Train 60%\", y_train),\n",
    "    (\"Valid 20%\", y_valid),\n",
    "    (\"Test 20%\", y_test)\n",
    "]:\n",
    "    counts = s.value_counts()\n",
    "    props = s.value_counts(normalize=True).round(3)\n",
    "    summary = pd.DataFrame({'count': counts, 'proportion': props})\n",
    "    print(f\"\\nSet: {name} (n={counts.sum()})\\n\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6adcf1",
   "metadata": {},
   "source": [
    "<a id=\"baseline\"></a>\n",
    "# 5. Modelo base: Dummy y heurística simple\n",
    "\n",
    "**Objetivo**  \n",
    "Definir puntos de referencia mínimos contra los cuales evaluar los modelos supervisados.  \n",
    "\n",
    "**Contexto**  \n",
    "Antes de entrenar clasificadores más sofisticados, es indispensable contar con *baselines* que indiquen qué tan lejos se está de una predicción trivial o de una simple regla de negocio.  \n",
    "\n",
    "**Importancia**  \n",
    "- **DummyClassifier (clase mayoritaria):** ignora todas las variables y siempre predice la clase más frecuente. Representa la *cota inferior* del desempeño esperado.  \n",
    "- **Heurística con `mb_used`:** regla basada en un único predictor (uso de MB). Fácil de explicar y aplicar en negocio, sirve para comparar si un modelo estadístico realmente aporta valor más allá de una regla operativa sencilla.  \n",
    "\n",
    "**Métricas y criterios**  \n",
    "- **Accuracy y Balanced Accuracy:** verifican si los modelos posteriores superan al predictor trivial.  \n",
    "- **F1-score:** evalúa la capacidad de capturar correctamente la clase positiva (caso de interés en negocio).  \n",
    "- **Matriz de confusión:** permite identificar los errores más comunes de cada baseline.  \n",
    "- **Comparación con la proporción mayoritaria:** ningún modelo debería rendir peor que el Dummy; cualquier mejora por encima de él es evidencia de valor añadido.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1818f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Dummy]: Modelo base que siempre predice la clase mayoritaria\n",
    "# Sirve como referencia mínima de desempeño: ningún modelo real debería rendir peor que esto.\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\n",
    "dummy.fit(X_train, y_train)\n",
    "_ = resumen(y_valid, dummy.predict(X_valid),\n",
    "            titulo='Modelo Dummy para predecir clase mayoritaria (valid)')\n",
    "\n",
    "# Extraemos el predictor 'mb_used' de cada partición (train, valid, test)\n",
    "# Lo convertimos en arrays de numpy para evaluarlo como regla heurística.\n",
    "mb_train, mb_valid, mb_test = [df['mb_used'].to_numpy() for df in (X_train, X_valid, X_test)]\n",
    "yv, yt = np.array(y_valid), np.array(y_test)\n",
    "\n",
    "# Definimos una rejilla de posibles umbrales (percentiles 1–99 de los valores en train)\n",
    "# Así probamos distintos puntos de corte para convertir 'mb_used' en predicciones binarias.\n",
    "candidatos = np.quantile(mb_train, np.linspace(0.01, 0.99, 99))\n",
    "\n",
    "def mejor_umbral(metric):\n",
    "    \"\"\"\n",
    "    Busca el umbral que maximiza una métrica dada (ej. Balanced Accuracy o F1).\n",
    "    Retorna el umbral óptimo y el score alcanzado en valid.\n",
    "    \"\"\"\n",
    "    scores = [metric(yv, (mb_valid >= t).astype(int)) for t in candidatos]\n",
    "    i = np.argmax(scores)\n",
    "    return candidatos[i], scores[i]\n",
    "\n",
    "# Métricas que nos interesa optimizar\n",
    "# - BACC: útil cuando las clases están desbalanceadas.\n",
    "# - F1: balance entre precisión y recall para la clase positiva.\n",
    "metricas = {\n",
    "    \"BACC\": lambda y,p: balanced_accuracy_score(y,p),\n",
    "    \"F1\":   lambda y,p: f1_score(y,p,pos_label=1)\n",
    "}\n",
    "\n",
    "# Evaluamos cada métrica: mejor umbral, score alcanzado y accuracy asociado\n",
    "# Guardamos resultados en un diccionario y mostramos resúmenes en valid.\n",
    "resultados = {}\n",
    "for nombre, metrica in metricas.items():\n",
    "    u, sc = mejor_umbral(metrica)\n",
    "    acc = accuracy_score(yv, (mb_valid >= u).astype(int))\n",
    "    resultados[nombre] = {\"umbral\": u, \"score\": sc, \"acc\": acc}\n",
    "    _ = resumen(y_valid, (mb_valid >= u).astype(int),\n",
    "                titulo=f\"Dummy: Heurística optimizada por {nombre} (valid, ACC={acc:.3f})\")\n",
    "\n",
    "# [Selección del Dummy optimizado]\n",
    "# Criterio: elegimos el modelo con mayor score, siempre que supere cierto mínimo de accuracy (>=0.75).\n",
    "ganador = max(resultados.items(),\n",
    "              key=lambda kv: (kv[1][\"acc\"] >= 0.75, kv[1][\"score\"]))\n",
    "criterio, datos = ganador\n",
    "u_final = datos[\"umbral\"]\n",
    "\n",
    "# [Evaluación final en TEST]\n",
    "# Probamos en test el umbral y criterio ganador, para ver su desempeño fuera de valid.\n",
    "_ = resumen(y_test, (mb_test >= u_final).astype(int),\n",
    "            titulo=f\"Dummy: Heurística elegida ({criterio}), umbral={u_final:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5912c",
   "metadata": {},
   "source": [
    "<a id=\"supervisados\"></a>\n",
    "# 6. Modelos base supervisados\n",
    "**Objetivo:**  \n",
    "Entrenar y evaluar tres clasificadores supervisados estándar (Regresión Logística, Árbol de Decisión y Random Forest) en configuración básica, obteniendo métricas iniciales de validación.  \n",
    "\n",
    "**Contexto:**  \n",
    "Tras los baselines triviales, es necesario comparar modelos de distinta naturaleza:  \n",
    "- **Regresión Logística:** lineal, interpretable, requiere escalado de features.  \n",
    "- **Árbol de Decisión:** no lineal, interpretable, robusto a escalas.  \n",
    "- **Random Forest:** ensamble de árboles, suele mejorar estabilidad y desempeño.  \n",
    "\n",
    "**Importancia:**  \n",
    "- **Comparación justa:** usar la misma partición (train/valid) para los tres modelos.  \n",
    "- **Escalado previo en LogReg:** evita problemas numéricos y asegura convergencia.  \n",
    "- **Resultados consistentes:** con la función `resumen` se comparan métricas en un mismo formato.  \n",
    "- **Diccionario `base_scores`:** conserva las exactitudes para futuras referencias.  \n",
    "\n",
    "**Métricas/criterios:**  \n",
    "- **Accuracy y Balanced Accuracy:** desempeño general y balanceado entre clases.  \n",
    "- **Reporte por clase:** diagnóstico detallado en Smart vs Ultra.  \n",
    "- **Comparación entre modelos:** ver cuál arranca con mejor base en validación.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62df6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Pipeline]: Regresión Logística con escalado y balanceo de clases\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('model', LogisticRegression(\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_iter=9999,\n",
    "        class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# [Pipeline]: Árbol de Decisión con balanceo\n",
    "pipe_dt = Pipeline([\n",
    "    ('model', DecisionTreeClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# [Pipeline]: Random Forest con balanceo\n",
    "pipe_rf = Pipeline([\n",
    "    ('model', RandomForestClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# [Entrenamiento y validación]: se evalúan los tres modelos\n",
    "base_scores_bal = {}\n",
    "for name, pipe in [\n",
    "    ('Logistic Regression (balanced)', pipe_lr), \n",
    "    ('Decision Tree (balanced)', pipe_dt), \n",
    "    ('Random Forest (balanced)', pipe_rf)\n",
    "]:\n",
    "    pipe.fit(X_train, y_train)                        \n",
    "    pred = pipe.predict(X_valid)                      \n",
    "    acc, *_ = resumen(y_valid, pred,                  \n",
    "                      titulo=f\"Modelo base {name}\")\n",
    "    base_scores_bal[name] = acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab0c576",
   "metadata": {},
   "source": [
    "## Resultados obtenidos en validación\n",
    "\n",
    "### Comparativa de métricas principales\n",
    "\n",
    "| Modelo              | Accuracy | Balanced Acc | Precisión (0) | Recall (0) | F1 (0) | Precisión (1) | Recall (1) | F1 (1) |\n",
    "|---------------------|:--------:|:------------:|:-------------:|:----------:|:------:|:-------------:|:----------:|:------:|\n",
    "| Logistic Regression |  0.641   |    0.632     |     0.79      |   0.66     |  0.72  |     0.44      |   0.61     |  0.51  |\n",
    "| Decision Tree       |  0.728   |    0.673     |     0.80      |   0.81     |  0.81  |     0.56      |   0.53     |  0.55  |\n",
    "| Random Forest       |  0.796   |    0.727     |     0.82      |   0.91     |  0.86  |     0.72      |   0.55     |  0.62  |\n",
    "\n",
    "---\n",
    "\n",
    "### Detalle por modelo\n",
    "\n",
    "**Logistic Regression (balanced)**  \n",
    "- Accuracy = **0.641**  \n",
    "- Smart (0): precision 0.79, recall 0.66, f1 0.72  \n",
    "- Ultra (1): precision 0.44, recall 0.61, f1 0.51  \n",
    "- **Interpretación:** el recall en Ultra mejora notablemente (0.21 → 0.61), aunque cae el accuracy global. Buen trade-off si la prioridad es no perder clientes Ultra.  \n",
    "\n",
    "---\n",
    "\n",
    "**Decision Tree (balanced)**  \n",
    "- Accuracy = **0.728**  \n",
    "- Smart (0): precision 0.80, recall 0.81, f1 0.81  \n",
    "- Ultra (1): precision 0.56, recall 0.53, f1 0.55  \n",
    "- **Interpretación:** mantiene un desempeño equilibrado, con recall en Ultra levemente inferior a Logistic Regression, pero mejor accuracy total.  \n",
    "\n",
    "---\n",
    "\n",
    "**Random Forest (balanced)**  \n",
    "- Accuracy = **0.796**  \n",
    "- Smart (0): precision 0.82, recall 0.91, f1 0.86  \n",
    "- Ultra (1): precision 0.72, recall 0.55, f1 0.62  \n",
    "- **Interpretación:** sigue siendo el más sólido en accuracy y mantiene buen balance; el recall en Ultra sube respecto al modelo sin balanceo.  \n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión preliminar\n",
    "\n",
    "- El balanceo de clases mejora el **recall de Ultra**, sobre todo en Logistic Regression.  \n",
    "- El costo es una ligera caída en accuracy (esperable en desbalance 70/30).  \n",
    "- **Random Forest (balanced)** continúa como el mejor modelo integral: combina alto accuracy con mejora en recall para Ultra.  \n",
    "- **Logistic Regression (balanced)** es útil si la prioridad absoluta es capturar la mayor cantidad de Ultras, aceptando pérdida de exactitud global.  \n",
    "\n",
    "**Siguiente paso:** realizar búsqueda de hiperparámetros en Random Forest con `class_weight=\"balanced\"` para confirmar si puede mantener este equilibrio en el set de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba5c45",
   "metadata": {},
   "source": [
    "<a id=\"optimizacion\"></a>\n",
    "# 7. Optimización de hiperparámetros (Random Forest)\n",
    "\n",
    "**Objetivo:**  \n",
    "Ajustar los hiperparámetros de Random Forest mediante validación cruzada estratificada, priorizando la **balanced accuracy** como criterio de selección para no subestimar la clase Ultra (minoritaria).  \n",
    "\n",
    "**Contexto:**  \n",
    "Entre los modelos base, Random Forest mostró el mejor desempeño. Por ello se concentra el esfuerzo de optimización en este algoritmo, buscando mayor estabilidad y mejor trade-off entre clases.  \n",
    "\n",
    "**Importancia:**  \n",
    "- **Validación cruzada (5 folds):** asegura robustez en la evaluación de combinaciones.  \n",
    "- **Espacio de búsqueda ampliado:** considera número de árboles, profundidad máxima, tamaño mínimo de hojas, criterios de división, selección de features y balanceo de clases.  \n",
    "- **RandomizedSearchCV:** permite explorar de forma eficiente 30 combinaciones aleatorias sin necesidad de un grid completo.  \n",
    "\n",
    "**Métricas/criterios:**  \n",
    "- **Balanced Accuracy:** criterio final de selección, más representativo en escenarios desbalanceados.  \n",
    "- **Accuracy en validación:** usado como referencia secundaria para confirmar que el modelo no pierde rendimiento global.  \n",
    "- **Reporte de parámetros óptimos:** asegura trazabilidad y reproducibilidad del modelo elegido.  \n",
    "\n",
    "[Volver al Índice](#indice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc59240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Validación]: 5 folds estratificados\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# [Espacio de búsqueda Random Forest ampliado]\n",
    "param_rf = {\n",
    "    'model__n_estimators': [500, 800, 1000],\n",
    "    'model__max_depth': [None, 5, 8, 10, 12, 16, 20],\n",
    "    'model__min_samples_leaf': [1, 2, 5],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__max_features': ['sqrt', 'log2'],\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "def run_search(scoring_name):\n",
    "    rs = RandomizedSearchCV(\n",
    "        pipe_rf,\n",
    "        param_distributions=param_rf,\n",
    "        n_iter=30,\n",
    "        cv=cv,\n",
    "        scoring=scoring_name,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    rs.fit(X_train, y_train)\n",
    "    best_rf = rs.best_estimator_\n",
    "    acc, bacc, prec, rec, f1, sup, cm, _ = resumen(\n",
    "        y_valid,\n",
    "        best_rf.predict(X_valid),\n",
    "        titulo=f\"Random Forest optimizado (valid, scoring={scoring_name})\"\n",
    "    )\n",
    "    return {\n",
    "        \"scoring\": scoring_name,\n",
    "        \"params\": rs.best_params_,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_acc\": bacc,\n",
    "        \"recall_ultra\": rec[1],\n",
    "        \"f1_ultra\": f1[1]\n",
    "    }, best_rf  # <- devuelves también el modelo\n",
    "\n",
    "# Ejecutar búsquedas con los dos criterios\n",
    "res_accuracy, _ = run_search(\"accuracy\") # solo el dict\n",
    "res_bacc, best_rf = run_search(\"balanced_accuracy\") # dict + modelo optimizado\n",
    "\n",
    "# Mostrar los mejores parámetros de forma legible\n",
    "print(\"\\n***Mejores parámetros RF (scoring=balanced_accuracy):***\\n\")\n",
    "for k, v in res_bacc[\"params\"].items():\n",
    "    print(f\"- {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc925562",
   "metadata": {},
   "source": [
    "## Resultados de la validación (Random Forest optimizado)\n",
    "\n",
    "### Mejores parámetros seleccionados (scoring = balanced_accuracy)\n",
    "\n",
    "- `model__n_estimators`: 800  \n",
    "- `model__min_samples_split`: 2  \n",
    "- `model__min_samples_leaf`: 5  \n",
    "- `model__max_features`: log2  \n",
    "- `model__max_depth`: None  \n",
    "- `model__class_weight`: balanced  \n",
    "\n",
    "Estos parámetros se **congelan** para la evaluación final en el set de test.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparativa de métricas principales\n",
    "\n",
    "| Scoring              | Accuracy | Balanced Acc | Precisión (0) | Recall (0) | F1 (0) | Precisión (1) | Recall (1) | F1 (1) |\n",
    "|----------------------|:--------:|:------------:|:-------------:|:----------:|:------:|:-------------:|:----------:|:------:|\n",
    "| Accuracy             |  0.815   |    0.742     |     0.825     |   0.930    |  0.875 |     0.779     |   0.553    |  0.647 |\n",
    "| Balanced Accuracy    |  0.793   |    0.743     |     0.837     |   0.872    |  0.854 |     0.680     |   0.614    |  0.645 |\n",
    "\n",
    "---\n",
    "\n",
    "### Detalle por configuración\n",
    "\n",
    "**Random Forest (scoring=accuracy)**  \n",
    "- Accuracy = **0.815**  \n",
    "- Smart (0): precision 0.825, recall 0.930, f1 0.875  \n",
    "- Ultra (1): precision 0.779, recall 0.553, f1 0.647  \n",
    "- **Interpretación:** maximiza la exactitud global, pero sigue sacrificando la clase Ultra (recall 0.553).  \n",
    "\n",
    "---\n",
    "\n",
    "**Random Forest (scoring=balanced_accuracy)**  \n",
    "- Accuracy = **0.793**  \n",
    "- Smart (0): precision 0.837, recall 0.872, f1 0.854  \n",
    "- Ultra (1): precision 0.680, recall 0.614, f1 0.645  \n",
    "- **Interpretación:** cede algo de accuracy global (~2.2 puntos), pero gana recall en Ultra (0.553 → 0.614), ofreciendo un modelo más equilibrado entre clases.  \n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión preliminar\n",
    "\n",
    "- **Scoring=accuracy:** prioriza la exactitud global, pero deja escapar demasiados clientes Ultra.  \n",
    "- **Scoring=balanced_accuracy:** mejora el recall de Ultra y mantiene métricas globales competitivas, alineándose mejor con el objetivo de negocio.  \n",
    "\n",
    "**Elección final:** se selecciona **Random Forest optimizado con `scoring=\"balanced_accuracy\"`** (parámetros arriba) como modelo definitivo a evaluar en el set de test.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28696ccc",
   "metadata": {},
   "source": [
    "<a id=\"evaluacion\"></a>\n",
    "# 8. Evaluación final en test\n",
    "\n",
    "**Objetivo:**  \n",
    "Evaluar el desempeño del modelo final (Random Forest optimizado) en el conjunto de prueba independiente, obteniendo métricas estándar y un intervalo de confianza robusto mediante bootstrap con reentrenamiento.  \n",
    "\n",
    "**Contexto:**  \n",
    "Una vez seleccionados y optimizados los hiperparámetros en `train+valid`, se reentrena el mejor modelo con todos esos datos para aprovechar la máxima información disponible antes de la evaluación en `test`.  \n",
    "\n",
    "**Importancia:**  \n",
    "- **Métricas en test:** entregan una estimación honesta del desempeño real sobre datos nunca vistos.  \n",
    "- **Bootstrap con reentrenamiento:** captura no solo la variabilidad de muestreo del test, sino también la del entrenamiento, ofreciendo un IC más realista.  \n",
    "- **Intervalo de confianza (95%):** aporta una medida de incertidumbre sobre la métrica principal, útil en reportes técnicos y ejecutivos.  \n",
    "\n",
    "**Métricas/criterios:**  \n",
    "- **Accuracy y Balanced Accuracy en test.**  \n",
    "- **Reporte de precisión, recall y F1 por clase.**  \n",
    "- **IC 95% (bootstrap con reentrenamiento):** rango esperado de accuracy.  \n",
    "\n",
    "[Volver al Índice](#indice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenar el mejor modelo (Random Forest optimizado) en train+valid\n",
    "X_tv = pd.concat([X_train, X_valid], axis=0)\n",
    "y_tv = pd.concat([y_train, y_valid], axis=0)\n",
    "best_rf.fit(X_tv, y_tv)\n",
    "\n",
    "# Evaluación estándar en test\n",
    "pred_test = best_rf.predict(X_test)\n",
    "print(\"*** Evaluación Final ***\")\n",
    "acc_std, *_ = resumen(y_test, pred_test, titulo=\"Modelo RF optimizado (test)\")\n",
    "\n",
    "# Bootstrap IC 95% para accuracy (con reentrenamiento)\n",
    "B = 300   \n",
    "n = len(y_tv)\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "boot = []\n",
    "\n",
    "# Guardar los hiperparámetros óptimos del pipeline completo\n",
    "best_params = best_rf.get_params()\n",
    "\n",
    "for _ in range(B):\n",
    "    # Remuestrear train+valid con reemplazo\n",
    "    idx = rng.integers(0, n, n)\n",
    "    Xb, yb = X_tv.iloc[idx], y_tv.iloc[idx]\n",
    "    \n",
    "    # Nueva instancia del pipeline con los mismos parámetros\n",
    "    pipe_b = Pipeline([('model', RandomForestClassifier())])\n",
    "    pipe_b.set_params(**best_params)\n",
    "    \n",
    "    # Reentrenar y evaluar\n",
    "    pipe_b.fit(Xb, yb)\n",
    "    pred_b = pipe_b.predict(X_test)\n",
    "    boot.append(accuracy_score(y_test, pred_b))\n",
    "\n",
    "low, high = np.percentile(boot, [2.5, 97.5])\n",
    "print(f\"\\nIC 95% accuracy (bootstrap con reentrenamiento): [{low:.3f}, {high:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c80a71",
   "metadata": {},
   "source": [
    "## Resultados de evaluación (Random Forest optimizado)\n",
    "\n",
    "### Métricas principales\n",
    "\n",
    "- Accuracy = **0.790**  \n",
    "- Balanced Accuracy = **0.748**  \n",
    "\n",
    "### Matriz de confusión (filas = verdad, columnas = predicción)\n",
    "\n",
    "|              | Pred. 0 | Pred. 1 |\n",
    "|--------------|---------|---------|\n",
    "| **Real 0**   |   382   |   64    |\n",
    "| **Real 1**   |   71    |   126   |\n",
    "\n",
    "### Desempeño por clase\n",
    "\n",
    "| Clase | Precisión | Recall | F1   | Soporte |\n",
    "|-------|-----------|--------|------|---------|\n",
    "| 0 (Smart) | 0.843     | 0.857  | 0.850 | 446     |\n",
    "| 1 (Ultra) | 0.663     | 0.640  | 0.651 | 197     |\n",
    "\n",
    "### Intervalo de confianza\n",
    "\n",
    "- IC 95% accuracy (bootstrap con reentrenamiento): **[0.764, 0.802]**\n",
    "\n",
    "---\n",
    "\n",
    "**Interpretación:**  \n",
    "El modelo final mantiene un buen balance: precisión alta para la clase mayoritaria (Smart) y un recall aceptable para Ultra (0.640), bastante mejor que baselines. El intervalo de confianza indica que el accuracy real esperado se encuentra estable en torno a 0.79.  \n",
    "\n",
    "---\n",
    "\n",
    "### Comparativa con baselines\n",
    "\n",
    "| Modelo                     | Accuracy | Balanced Acc | Precisión (0) | Recall (0) | F1 (0) | Precisión (1) | Recall (1) | F1 (1) |\n",
    "|-----------------------------|:--------:|:------------:|:-------------:|:----------:|:------:|:-------------:|:----------:|:------:|\n",
    "| Dummy (mayoría)            |  0.694   |    0.500     |     0.694     |   1.000    |  0.820 |     0.000     |   0.000    |  0.000 |\n",
    "| Heurística MB (umbral ópt.)|  0.593   |    0.617     |     0.747     |   0.675    |  0.709 |     0.270     |   0.558    |  0.362 |\n",
    "| RF optimizado (final)      |  0.790   |    0.748     |     0.843     |   0.857    |  0.850 |     0.663     |   0.640    |  0.651 |\n",
    "\n",
    "**Conclusión comparativa:**  \n",
    "- El **Dummy** marca la cota mínima: incapaz de predecir Ultras.  \n",
    "- El modelo **heurístico** mejora recall en Ultra pero sacrifica accuracy global.  \n",
    "- El **Random Forest optimizado** domina en todas las métricas clave, logrando un equilibrio robusto entre clases y un desempeño realista en test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97681352",
   "metadata": {},
   "source": [
    "<a id=\"cordura\"></a>\n",
    "# 9. Pruebas de cordura\n",
    "**Objetivo:**  \n",
    "Confirmar que el modelo final (Random Forest optimizado) funciona de manera coherente, que no depende de errores o fugas de información, y que sus predicciones tienen sentido tanto práctico como estadístico.  \n",
    "\n",
    "**Contexto:**  \n",
    "Aunque las métricas en `test` ya son buenas, siempre es recomendable realizar pruebas adicionales para descartar trampas involuntarias y para validar la interpretabilidad del modelo. Aquí se combinan **pruebas básicas** (rápidas y lógicas) con **pruebas avanzadas** (más técnicas y visuales).  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe4de9",
   "metadata": {},
   "source": [
    "<a id=\"cordura-basicas\"></a>\n",
    "## 9.1 Pruebas básicas (caja negra)\n",
    "\n",
    "1. **Predicción constante**  \n",
    "   Verificamos que el modelo no esté prediciendo siempre la clase mayoritaria.  \n",
    "   - Esperado: el modelo predice ambas clases (0=Smart, 1=Ultra).  \n",
    "\n",
    "2. **Distribución de predicciones vs real**  \n",
    "   Comparamos la proporción real de clases con la proporción de predicciones.  \n",
    "   - Esperado: proporciones similares; si hay desviación fuerte, el modelo podría estar sesgado.  \n",
    "\n",
    "3. **Baseline aleatorio**  \n",
    "   Simulamos un modelo que asigna etiquetas al azar.  \n",
    "   - Esperado: accuracy cercano a 0.5 (azar puro). El RF debe superarlo ampliamente.  \n",
    "\n",
    "4. **Bootstrap de accuracy**  \n",
    "   Calculamos un IC 95% para accuracy repitiendo muestreo del test set.  \n",
    "   - Esperado: un intervalo relativamente estrecho alrededor de la métrica observada.  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ¿El modelo predice solo una clase?\n",
    "unique_preds, counts = np.unique(pred_test, return_counts=True)\n",
    "print(\"Clases predichas en test:\", dict(zip(unique_preds, counts)))\n",
    "\n",
    "# 2. Distribución de predicciones vs distribución real\n",
    "print(\"\\nDistribución real (test):\", y_test.value_counts(normalize=True).to_dict())\n",
    "print(\"Distribución predicha (test):\",\n",
    "      pd.Series(pred_test).value_counts(normalize=True).to_dict())\n",
    "\n",
    "# 3. Baseline aleatorio\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "rand_preds = rng.integers(0, 2, size=len(y_test))\n",
    "acc_rand = accuracy_score(y_test, rand_preds)\n",
    "print(f\"\\nAccuracy baseline aleatorio: {acc_rand:.3f}\")\n",
    "\n",
    "# 4. Intervalo bootstrap ya calculado arriba\n",
    "print(f\"\\nIC 95% accuracy (bootstrap, estándar): [{low:.3f}, {high:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e879bc",
   "metadata": {},
   "source": [
    "<a id=\"cordura-avanzadas\"></a>\n",
    "## 9.2 Pruebas avanzadas (diagnóstico profundo)\n",
    "\n",
    "1. **Barajado de etiquetas (sanity check extremo)**  \n",
    "   Se reentrena el modelo con las etiquetas aleatoriamente barajadas.  \n",
    "   - **Esperado:** el accuracy debe caer a ~0.5 (azar puro). Si el valor es mayor, puede existir fuga de información.  \n",
    "\n",
    "2. **Importancia por permutación**  \n",
    "   Se calcula la contribución real de cada feature en el desempeño del modelo, evaluando cómo cambia la métrica al alterar aleatoriamente sus valores.  \n",
    "   - **Esperado:** `mb_used` debe aparecer como la variable más relevante, lo cual coincide con la intuición de negocio (a mayor uso de MB, más probabilidad de migrar a Ultra).  \n",
    "\n",
    "3. **Curvas ROC y PR**  \n",
    "   Se grafican las curvas ROC (tasa de verdaderos positivos vs tasa de falsos positivos) y PR (precisión vs recall).  \n",
    "   - **Esperado:**  \n",
    "     - La curva ROC debe ubicarse por encima de la diagonal aleatoria.  \n",
    "     - La curva Precision-Recall debe quedar por encima de la línea base (proporción de la clase positiva = Ultra).  \n",
    "\n",
    "[Volver al Índice](#indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f28c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Repetir varias veces la prueba de etiquetas barajadas\n",
    "B = 20\n",
    "accs, baccs, aucs = [], [], []\n",
    "\n",
    "for b in range(B):\n",
    "    # Barajar etiquetas\n",
    "    y_tv_shuf = y_tv.sample(frac=1.0, random_state=RANDOM_STATE + b)\n",
    "    rf_shuf = RandomForestClassifier(random_state=RANDOM_STATE + b, n_jobs=-1)\n",
    "    rf_shuf.fit(X_tv, y_tv_shuf)\n",
    "    \n",
    "    # Predicciones en test\n",
    "    pred_shuf = rf_shuf.predict(X_test)\n",
    "    probs_shuf = rf_shuf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    accs.append(accuracy_score(y_test, pred_shuf))\n",
    "    baccs.append(balanced_accuracy_score(y_test, pred_shuf))\n",
    "    aucs.append(roc_auc_score(y_test, probs_shuf))\n",
    "\n",
    "print(f\"Promedio accuracy (shuffle): {np.mean(accs):.3f}\")\n",
    "print(f\"Promedio balanced acc (shuffle): {np.mean(baccs):.3f}\")\n",
    "print(f\"Promedio ROC AUC (shuffle): {np.mean(aucs):.3f}\")\n",
    "\n",
    "# 2. Comparar contra DummyClassifier\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\n",
    "dummy.fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "probs_dummy = np.full_like(y_test, fill_value=0)  # dummy siempre predice 0\n",
    "\n",
    "print(\"\\nDummyClassifier:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_dummy):.3f}\")\n",
    "print(f\"Balanced Acc: {balanced_accuracy_score(y_test, pred_dummy):.3f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, probs_dummy):.3f}\")\n",
    "\n",
    "# 2. Permutation importance\n",
    "try:\n",
    "    result = permutation_importance(best_rf, X_test, y_test, n_repeats=20,\n",
    "                                    random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    importances = pd.Series(result.importances_mean, index=features).sort_values(ascending=False)\n",
    "    print('\\nImportancias por permutación (test):\\n', importances)\n",
    "    plt.figure()\n",
    "    importances.sort_values().plot(kind='barh')\n",
    "    plt.title('Importancia por permutación (test)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Permutation importance no disponible:', str(e))\n",
    "\n",
    "# 3. Curvas ROC y PR\n",
    "if hasattr(best_rf, \"predict_proba\"):\n",
    "    probs = best_rf.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    prec, rec, _ = precision_recall_curve(y_test, probs)\n",
    "    \n",
    "    # ROC\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0,1],[0,1], 'k--', label=\"Random\")\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('Curva ROC (diagnóstico)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # PR\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec, label=\"PR Curve\")\n",
    "    baseline = y_test.mean()\n",
    "    plt.hlines(baseline, 0, 1, colors='r', linestyles='--', label=\"Baseline\")\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Curva Precision-Recall (diagnóstico)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af52b30",
   "metadata": {},
   "source": [
    "**Validación rápida**  \n",
    "- Pruebas de cordura básicas correctas.  \n",
    "- Curvas generadas sin error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e140998",
   "metadata": {},
   "source": [
    "<a id=\"conclusiones\"></a>\n",
    "# 10. Conclusiones\n",
    "\n",
    "**1. Desempeño global del modelo**  \n",
    "- El **Random Forest optimizado** alcanzó **Accuracy = 0.790** en test, con **IC 95% ≈ [0.764, 0.802]**, superando claramente los baselines (Dummy ≈ 0.694; Heurística por MB ≈ 0.593 en test).  \n",
    "- El modelo **predice ambas clases**. La proporción predicha de **Ultra ≈ 29.5%** queda muy cercana a la real (**30.6%**), sin colapso hacia la clase mayoritaria.\n",
    "\n",
    "**2. Pruebas de cordura básicas**  \n",
    "- Supera ampliamente al azar (**accuracy aleatorio ≈ 0.462**).  \n",
    "- La distribución de clases predicha es consistente con la real y no muestra sesgo extremo.  \n",
    "- El bootstrap confirma estabilidad del desempeño (**IC 95% de accuracy ≈ [0.764, 0.802]**).\n",
    "\n",
    "**3. Pruebas de cordura avanzadas**  \n",
    "- **Barajado de etiquetas (20 repeticiones):** el **accuracy** ronda ~0.66 por el desbalance, pero **Balanced Accuracy ≈ 0.514** y **ROC AUC ≈ 0.505** caen a ~0.5, lo que **descarta fuga de información**.  \n",
    "- **Importancia por permutación:** `mb_used` emerge como el predictor dominante; el resto aporta señal secundaria.  \n",
    "- **Curvas ROC y PR:** poder discriminativo claro (ROC por encima de la diagonal; PR por encima del baseline de **0.306**).\n",
    "\n",
    "**4. Implicaciones de negocio**  \n",
    "- El modelo es **útil para priorizar clientes con alta probabilidad de migrar a Ultra**; mantiene un perfil conservador con **recall en Ultra ≈ 0.640** (vs **0.857** en Smart).  \n",
    "- Si la prioridad es **no perder Ultras**, puede **ajustarse el umbral** con `predict_proba` para ganar recall aceptando menor precisión. Dado que la proporción predicha ya quedó cercana a la real, el ajuste es una **palanca opcional**, no un requisito.  \n",
    "- **Consumo de MB** es la variable clave; las acciones comerciales enfocadas en usuarios con altos consumos tendrán mayor impacto.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusión final**\n",
    "El Random Forest optimizado es **robusto, consistente y alineado con negocio**: supera baselines, no muestra fuga de información y captura la señal más relevante (`mb_used`).  \n",
    "El siguiente paso es **definir el umbral operativo** según la tolerancia a falsos negativos en Ultra y trazar las campañas sobre segmentos de alto consumo de datos.\n",
    "\n",
    "[Volver al Índice](#indice)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
